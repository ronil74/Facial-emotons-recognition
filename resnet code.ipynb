{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH = 'fer2013.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>pixels</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion                                             pixels     Usage\n",
       "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training\n",
       "1        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training\n",
       "2        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training\n",
       "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training\n",
       "4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_size = (48, 48)\n",
    "data = pd.read_csv(FILE_PATH)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixels = data['pixels'].tolist()\n",
    "width, height = image_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images and emotions \n",
    "faces = []\n",
    "\n",
    "for p in pixels:\n",
    "    face = [int(pix) for pix in p.split(' ')]\n",
    "    face = np.asarray(face).reshape(width, height)\n",
    "    face = cv2.resize(face.astype('uint8'), image_size)\n",
    "    faces.append(face.astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35887"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces = np.asarray(faces)\n",
    "faces = np.expand_dims(faces, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35887, 7)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "emotions = pd.get_dummies(data['emotion']).values\n",
    "emotions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x, v2=True):  # v2 to keep the image btw. -1 and 1\n",
    "    x = x.astype('float32')\n",
    "    x = x/255.0\n",
    "    if v2:\n",
    "        x = (x - 0.5)*2.0\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces = preprocess(faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(faces, emotions,test_size=0.2,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import layers\n",
    "from keras.layers import Activation, Convolution2D, Conv2D, Dropout, AveragePooling2D, BatchNormalization, GlobalAveragePooling2D, Flatten, Input, MaxPooling2D, SeparableConv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 100\n",
    "image_shape = (48, 48, 1)\n",
    "verbose = True \n",
    "num_class = 7\n",
    "patience = 50  # number of epochs with no improvement after which training will be stopped\n",
    "base_path = 'models/'\n",
    "l2_regularization = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator = ImageDataGenerator(featurewise_center=False, featurewise_std_normalization=False, rotation_range=10, \n",
    "                                    width_shift_range=0.1, height_shift_range=0.1, zoom_range=.1, horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "regularization = l2(l2_regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "image_input = Input(image_shape)\n",
    "x = Conv2D(filters=8, kernel_size=(3,3), strides=(1,1), kernel_regularizer=regularization, use_bias=False)(image_input)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(filters=8, kernel_size=(3,3), strides=(1,1), kernel_regularizer=regularization, use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "# module 1\n",
    "# residual module \n",
    "residual = Conv2D(filters=16, kernel_size=(1,1), strides=(2,2), padding='same', use_bias=False)(x)\n",
    "residual = BatchNormalization()(residual)\n",
    "\n",
    "x = SeparableConv2D(filters=16, kernel_size=(3,3), padding='same', kernel_regularizer=regularization, use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = SeparableConv2D(filters=16, kernel_size=(3,3), padding='same', kernel_regularizer=regularization, use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='same')(x)\n",
    "x = layers.add([x,residual])\n",
    "\n",
    "# module 2\n",
    "# residual module \n",
    "residual = Conv2D(filters=32, kernel_size=(1,1), strides=(2,2), padding='same', use_bias=False)(x)\n",
    "residual = BatchNormalization()(residual)\n",
    "\n",
    "x = SeparableConv2D(filters=32, kernel_size=(3,3), padding='same', kernel_regularizer=regularization, use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = SeparableConv2D(filters=32, kernel_size=(3,3), padding='same', kernel_regularizer=regularization, use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='same')(x)\n",
    "x = layers.add([x,residual])\n",
    "\n",
    "# module 3\n",
    "# residual module \n",
    "residual = Conv2D(filters=64, kernel_size=(1,1), strides=(2,2), padding='same', use_bias=False)(x)\n",
    "residual = BatchNormalization()(residual)\n",
    "\n",
    "x = SeparableConv2D(filters=64, kernel_size=(3,3), padding='same', kernel_regularizer=regularization, use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = SeparableConv2D(filters=64, kernel_size=(3,3), padding='same', kernel_regularizer=regularization, use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='same')(x)\n",
    "x = layers.add([x,residual])\n",
    "\n",
    "# module 4\n",
    "# residual module \n",
    "residual = Conv2D(filters=128, kernel_size=(1,1), strides=(2,2), padding='same', use_bias=False)(x)\n",
    "residual = BatchNormalization()(residual)\n",
    "\n",
    "x = SeparableConv2D(filters=128, kernel_size=(3,3), padding='same', kernel_regularizer=regularization, use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = SeparableConv2D(filters=128, kernel_size=(3,3), padding='same', kernel_regularizer=regularization, use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='same')(x)\n",
    "x = layers.add([x,residual])\n",
    "\n",
    "x = Conv2D(filters=num_class, kernel_size=(3,3), padding='same')(x)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "output = Activation('softmax', name='predictions')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 48, 48, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 46, 46, 8)    72          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 46, 46, 8)    32          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 46, 46, 8)    0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 44, 44, 8)    576         activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 44, 44, 8)    32          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 44, 44, 8)    0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d (SeparableConv (None, 44, 44, 16)   200         activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 44, 44, 16)   64          separable_conv2d[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 44, 44, 16)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_1 (SeparableCo (None, 44, 44, 16)   400         activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 44, 44, 16)   64          separable_conv2d_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 22, 22, 16)   128         activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 22, 22, 16)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 22, 22, 16)   64          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 22, 22, 16)   0           max_pooling2d[0][0]              \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2 (SeparableCo (None, 22, 22, 32)   656         add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 22, 22, 32)   128         separable_conv2d_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 22, 22, 32)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_3 (SeparableCo (None, 22, 22, 32)   1312        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 22, 22, 32)   128         separable_conv2d_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 11, 11, 32)   512         add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 11, 11, 32)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 11, 11, 32)   128         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 11, 11, 32)   0           max_pooling2d_1[0][0]            \n",
      "                                                                 batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_4 (SeparableCo (None, 11, 11, 64)   2336        add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 11, 11, 64)   256         separable_conv2d_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 11, 11, 64)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_5 (SeparableCo (None, 11, 11, 64)   4672        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 11, 11, 64)   256         separable_conv2d_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 6, 6, 64)     2048        add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 6, 6, 64)     0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 6, 6, 64)     256         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 6, 6, 64)     0           max_pooling2d_2[0][0]            \n",
      "                                                                 batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_6 (SeparableCo (None, 6, 6, 128)    8768        add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 6, 6, 128)    512         separable_conv2d_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 6, 6, 128)    0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_7 (SeparableCo (None, 6, 6, 128)    17536       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 6, 6, 128)    512         separable_conv2d_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 3, 3, 128)    8192        add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 128)    0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 3, 3, 128)    512         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 3, 3, 128)    0           max_pooling2d_3[0][0]            \n",
      "                                                                 batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 3, 3, 7)      8071        add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 7)            0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Activation)        (None, 7)            0           global_average_pooling2d[0][0]   \n",
      "==================================================================================================\n",
      "Total params: 58,423\n",
      "Trainable params: 56,951\n",
      "Non-trainable params: 1,472\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(image_input, output)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "898/898 [==============================] - 174s 192ms/step - loss: 1.8078 - accuracy: 0.3300 - val_loss: 1.5379 - val_accuracy: 0.4416\n",
      "Epoch 2/100\n",
      "898/898 [==============================] - 174s 193ms/step - loss: 1.4227 - accuracy: 0.4705 - val_loss: 1.3969 - val_accuracy: 0.4911\n",
      "Epoch 3/100\n",
      "898/898 [==============================] - 173s 192ms/step - loss: 1.3007 - accuracy: 0.5196 - val_loss: 1.4443 - val_accuracy: 0.4726\n",
      "Epoch 4/100\n",
      "898/898 [==============================] - 175s 195ms/step - loss: 1.2078 - accuracy: 0.5533 - val_loss: 1.3692 - val_accuracy: 0.5085\n",
      "Epoch 5/100\n",
      "898/898 [==============================] - 173s 192ms/step - loss: 1.1493 - accuracy: 0.5747 - val_loss: 1.2588 - val_accuracy: 0.5425\n",
      "Epoch 6/100\n",
      "898/898 [==============================] - 173s 193ms/step - loss: 1.0955 - accuracy: 0.6014 - val_loss: 1.1894 - val_accuracy: 0.5722\n",
      "Epoch 7/100\n",
      "898/898 [==============================] - 172s 192ms/step - loss: 1.0477 - accuracy: 0.6159 - val_loss: 1.2522 - val_accuracy: 0.5504\n",
      "Epoch 8/100\n",
      "898/898 [==============================] - 175s 195ms/step - loss: 1.0040 - accuracy: 0.6364 - val_loss: 1.2674 - val_accuracy: 0.5447\n",
      "Epoch 9/100\n",
      "898/898 [==============================] - 173s 193ms/step - loss: 0.9625 - accuracy: 0.6484 - val_loss: 1.2559 - val_accuracy: 0.5567\n",
      "Epoch 10/100\n",
      "898/898 [==============================] - 173s 193ms/step - loss: 0.9365 - accuracy: 0.6578 - val_loss: 1.2145 - val_accuracy: 0.5628\n",
      "Epoch 11/100\n",
      "898/898 [==============================] - 175s 195ms/step - loss: 0.8833 - accuracy: 0.6797 - val_loss: 1.3572 - val_accuracy: 0.5393\n",
      "Epoch 12/100\n",
      "898/898 [==============================] - 175s 195ms/step - loss: 0.8435 - accuracy: 0.6945 - val_loss: 1.3789 - val_accuracy: 0.5463\n",
      "Epoch 13/100\n",
      "898/898 [==============================] - 175s 194ms/step - loss: 0.8095 - accuracy: 0.7052 - val_loss: 1.4564 - val_accuracy: 0.5288\n",
      "Epoch 14/100\n",
      "898/898 [==============================] - 176s 196ms/step - loss: 0.7733 - accuracy: 0.7265 - val_loss: 1.4244 - val_accuracy: 0.5389\n",
      "Epoch 15/100\n",
      "898/898 [==============================] - 176s 196ms/step - loss: 0.7429 - accuracy: 0.7319 - val_loss: 1.3010 - val_accuracy: 0.5744\n",
      "Epoch 16/100\n",
      "898/898 [==============================] - 175s 195ms/step - loss: 0.7098 - accuracy: 0.7489 - val_loss: 1.4490 - val_accuracy: 0.5340\n",
      "Epoch 17/100\n",
      "898/898 [==============================] - 174s 193ms/step - loss: 0.6646 - accuracy: 0.7659 - val_loss: 1.4000 - val_accuracy: 0.5532\n",
      "Epoch 18/100\n",
      "898/898 [==============================] - 174s 194ms/step - loss: 0.6498 - accuracy: 0.7741 - val_loss: 1.3782 - val_accuracy: 0.5541\n",
      "Epoch 19/100\n",
      "898/898 [==============================] - 175s 195ms/step - loss: 0.6418 - accuracy: 0.7767 - val_loss: 1.5419 - val_accuracy: 0.5270\n",
      "Epoch 20/100\n",
      "898/898 [==============================] - 175s 195ms/step - loss: 0.6088 - accuracy: 0.7881 - val_loss: 1.4500 - val_accuracy: 0.5638\n",
      "Epoch 21/100\n",
      "898/898 [==============================] - 175s 195ms/step - loss: 0.5652 - accuracy: 0.8008 - val_loss: 1.5484 - val_accuracy: 0.5552\n",
      "Epoch 22/100\n",
      "898/898 [==============================] - 176s 196ms/step - loss: 0.5541 - accuracy: 0.8065 - val_loss: 1.5735 - val_accuracy: 0.5489\n",
      "Epoch 23/100\n",
      "898/898 [==============================] - 175s 195ms/step - loss: 0.5222 - accuracy: 0.8208 - val_loss: 1.5886 - val_accuracy: 0.5592\n",
      "Epoch 24/100\n",
      "898/898 [==============================] - 174s 194ms/step - loss: 0.5078 - accuracy: 0.8212 - val_loss: 1.5560 - val_accuracy: 0.5549\n",
      "Epoch 25/100\n",
      "898/898 [==============================] - 169s 188ms/step - loss: 0.4922 - accuracy: 0.8295 - val_loss: 1.5753 - val_accuracy: 0.5561\n",
      "Epoch 26/100\n",
      "898/898 [==============================] - 168s 187ms/step - loss: 0.4755 - accuracy: 0.8384 - val_loss: 1.7102 - val_accuracy: 0.5587\n",
      "Epoch 27/100\n",
      "898/898 [==============================] - 165s 184ms/step - loss: 0.4505 - accuracy: 0.8489 - val_loss: 1.7341 - val_accuracy: 0.5504\n",
      "Epoch 28/100\n",
      "898/898 [==============================] - 164s 183ms/step - loss: 0.4373 - accuracy: 0.8539 - val_loss: 1.7177 - val_accuracy: 0.5506\n",
      "Epoch 29/100\n",
      "898/898 [==============================] - 165s 184ms/step - loss: 0.4157 - accuracy: 0.8602 - val_loss: 1.7484 - val_accuracy: 0.5486\n",
      "Epoch 30/100\n",
      "898/898 [==============================] - 164s 182ms/step - loss: 0.4077 - accuracy: 0.8613 - val_loss: 1.8201 - val_accuracy: 0.5329\n",
      "Epoch 31/100\n",
      "898/898 [==============================] - 156s 173ms/step - loss: 0.3958 - accuracy: 0.8653 - val_loss: 1.7352 - val_accuracy: 0.5552\n",
      "Epoch 32/100\n",
      "898/898 [==============================] - 156s 174ms/step - loss: 0.3814 - accuracy: 0.8736 - val_loss: 1.8900 - val_accuracy: 0.5571\n",
      "Epoch 33/100\n",
      "898/898 [==============================] - 165s 184ms/step - loss: 0.3846 - accuracy: 0.8720 - val_loss: 1.8166 - val_accuracy: 0.5496\n",
      "Epoch 34/100\n",
      "898/898 [==============================] - 164s 183ms/step - loss: 0.3756 - accuracy: 0.8735 - val_loss: 1.9016 - val_accuracy: 0.5463\n",
      "Epoch 35/100\n",
      "898/898 [==============================] - 163s 182ms/step - loss: 0.3585 - accuracy: 0.8811 - val_loss: 1.9362 - val_accuracy: 0.5517\n",
      "Epoch 36/100\n",
      "898/898 [==============================] - 166s 185ms/step - loss: 0.3447 - accuracy: 0.8861 - val_loss: 1.8704 - val_accuracy: 0.5548\n",
      "Epoch 37/100\n",
      "898/898 [==============================] - 165s 184ms/step - loss: 0.3389 - accuracy: 0.8895 - val_loss: 2.0117 - val_accuracy: 0.5577\n",
      "Epoch 38/100\n",
      "898/898 [==============================] - 165s 184ms/step - loss: 0.3278 - accuracy: 0.8928 - val_loss: 1.9478 - val_accuracy: 0.5599\n",
      "Epoch 39/100\n",
      "898/898 [==============================] - 167s 186ms/step - loss: 0.3302 - accuracy: 0.8916 - val_loss: 1.9938 - val_accuracy: 0.5550\n",
      "Epoch 40/100\n",
      "898/898 [==============================] - 164s 183ms/step - loss: 0.3168 - accuracy: 0.8990 - val_loss: 2.1274 - val_accuracy: 0.5461\n",
      "Epoch 41/100\n",
      "898/898 [==============================] - 165s 184ms/step - loss: 0.3171 - accuracy: 0.8975 - val_loss: 2.0578 - val_accuracy: 0.5552\n",
      "Epoch 42/100\n",
      "898/898 [==============================] - 163s 181ms/step - loss: 0.3028 - accuracy: 0.9033 - val_loss: 2.0765 - val_accuracy: 0.5620\n",
      "Epoch 43/100\n",
      "898/898 [==============================] - 165s 183ms/step - loss: 0.3103 - accuracy: 0.8995 - val_loss: 2.0470 - val_accuracy: 0.5539\n",
      "Epoch 44/100\n",
      "898/898 [==============================] - 166s 185ms/step - loss: 0.2864 - accuracy: 0.9081 - val_loss: 2.0505 - val_accuracy: 0.5539\n",
      "Epoch 45/100\n",
      "898/898 [==============================] - 162s 181ms/step - loss: 0.2903 - accuracy: 0.9076 - val_loss: 2.2180 - val_accuracy: 0.5343\n",
      "Epoch 46/100\n",
      "898/898 [==============================] - 165s 184ms/step - loss: 0.2874 - accuracy: 0.9083 - val_loss: 2.1712 - val_accuracy: 0.5521\n",
      "Epoch 47/100\n",
      "898/898 [==============================] - 164s 183ms/step - loss: 0.2727 - accuracy: 0.9137 - val_loss: 2.1750 - val_accuracy: 0.5485\n",
      "Epoch 48/100\n",
      "898/898 [==============================] - 167s 186ms/step - loss: 0.2664 - accuracy: 0.9151 - val_loss: 2.1407 - val_accuracy: 0.5488\n",
      "Epoch 49/100\n",
      "897/898 [============================>.] - ETA: 0s - loss: 0.3059 - accuracy: 0.8981"
     ]
    }
   ],
   "source": [
    "model.fit(xtrain, ytrain, validation_data=(xtest, ytest), epochs=100, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"emodel.json\", \"w\") as json_file:\n",
    "   json_file.write(model_json)\n",
    "model.save_weights(\"emodel.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import model_from_json\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "model = model_from_json(open(\"emodel.json\", \"r\").read())\n",
    "model.load_weights('emodel.h5')\n",
    "face_haar_cascade = cv2.CascadeClassifier(r'F:\\ronil be project\\project\\facial emotion\\haarcascade_frontalface_default.xml')\n",
    "print(5)\n",
    "model.save(\"emodel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from time import sleep\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing import image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "print(5)\n",
    "classifier =load_model('emodel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = ['angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral']\n",
    "cap=cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, image = cap.read()\n",
    "\n",
    "    converted_image= cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "    faces_detected = face_haar_cascade.detectMultiScale(converted_image)\n",
    "    for (x,y,w,h) in faces_detected:\n",
    "        cv2.rectangle(image,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        roi_gray = converted_image[y:y+h,x:x+w]\n",
    "        roi_gray = cv2.resize(roi_gray,(48,48),interpolation=cv2.INTER_AREA)\n",
    "    # rect,face,image = face_detector(frame)\n",
    "\n",
    "\n",
    "        if np.sum([roi_gray])!=0:\n",
    "            roi = roi_gray.astype('float')/255.0\n",
    "            roi = img_to_array(roi)\n",
    "            roi = np.expand_dims(roi,axis=0)\n",
    "\n",
    "        # make a prediction on the ROI, then lookup the class\n",
    "\n",
    "            preds = classifier.predict(roi)[0]\n",
    "            label=class_labels[preds.argmax()]\n",
    "            label_position = (x,y)\n",
    "            cv2.putText(image,label,label_position,cv2.FONT_HERSHEY_SIMPLEX,2,(0,255,0),3)\n",
    "        else:\n",
    "            cv2.putText(image,'No Face Found',(20,60),cv2.FONT_HERSHEY_SIMPLEX,2,(0,255,0),3)\n",
    "    cv2.imshow('Emotion Detector',image)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
